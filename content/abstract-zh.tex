% !Mode:: "TeX:UTF-8"

% 中英文摘要
\begin{cabstract}

	问答匹配是自然语言理解中的一个重要的研究领域，有着广泛地实际落地应用，例如信息检索、智能问答以及对话系统等领域。
	问答匹配主要包含两个子任务：答案选择任务和问句复述识别任务。
	答案选择任务要求模型评估“问题-答案”之间的语义相关性，
	主要用于优化对于目标问题进行相关答案召回的质量；
	问句复述识别任务需要模型判定“问题-问题”之间的语义一致性，
	以此提高对于目标问题召回已知答案的同义问题的精度。
	现有的匹配方法基于预训练语言模型，将“文本对子”形成基于上下文的统一编码表示，进行分类。
	然而，单纯依靠预训练语言模型将面临1) 表征能力弱，难解困难样本；2) 问句意图感知能力差，两种局限性。


	本文基于上述问题展开以下三个方面的具体研究：
	1) 微调预训练模型的表征能力仍然难以解决答案选择任务中的困难样本。
	对抗样本在问答匹配任务上具有着良好的表现，但现有的方法粒度单一，产生的样本质量不高。
	因此，本文设计了双粒度的对抗训练方法，生成高质量的对抗样本，有效地提高模型的语义表征能力。
	% 1）预训练语言模型并未有效利用词块、短语和子句的独立语义信息表示，使其在匹配过程中容易错失精细粒度语义的感知。
	% 因此，本文提出一种多粒度交互推理网络，该方法对问题与答案进行多粒度语义编码，以丰富句子间的语义信息；
	2) 问句复述识别面临着“同质异构”以及“异质同构”样本难解的问题。传统的难样本生成方法存在时间效率低，生成质量差等问题。
	为此，我们设计了一种生成式的数据增强策略，显著提高了生成效率和质量。
	并且本文提供了“错题本”的训练方法，对于难解样本举一反三，简单有效地提高模型性能。
	% 预训练语言模型对特定任务的精细语义感知依赖于其微调数据的数量与质量。
	% 为此，本文提出一种定向数据增强策略，该方法利用诱导标签对生成网络进行引导，促进问题复述识别数据的自动扩展。
	% 与传统数据增强方法相比，本文方法生成样本的质量更高、语义表达更加多元化；
	3) 现有的预训练语言模型方法在解决问句复述识别问题时，没有有效利用问句的意图信息，例如时间，地点，做法等。
	导致模型忽视了意图信息，而容易被字面上的相近或差异所迷惑。
	为此，本文设计了基于变分自编码器的问句意图增强模型，有效地提升模型对于问句意图的感知能力。
	% 3）现有的研究缺乏对模型鲁棒性的深入探讨，尤其在数据资源相对稀缺的中文领域，模型的鲁棒性更加难以评定。
	% % 导致许多模型只能在特定的实验数据上呈现准确的结果，在实际应用中的表现却并不理想。
	% 为此，本文构建了一个符合中文语言学特征的评估数据集CQM$_{robust}$，
	% 其能够按照中文语言现象对问题复述识别模型进行系统化的鲁棒性测试，
	% 有助于分析现有预训练语言模型在该任务上的优势与不足。

	本文从对抗训练、生成式增强学习以及问句意图增强三个角度出发，一定程度上缓解了问答匹配领域中模型表征能力弱和问句意图感知能力差的问题。
	在公开数据集WPQA、TREC-QA、LCQMC、BQ和QQP上的实验证明了本文方法的有效性。
	\vskip 10bp
	\noindent
	{\heiti\zihao{-4} 关键词：}
	问答匹配，
	答案选择，
	问句复述识别，
	数据增强，
	意图识别
	
	\begin{flushright}
		{\heiti\zihao{-4} 作~~~~~~~~者：}金志凌

		{\heiti\zihao{-4} 指导老师：}洪~~~~宇
	\end{flushright}
	% \begin{flushright}
	% 	{\heiti\zihao{-4} 作~~~~~~~~者：}***

	% 	{\heiti\zihao{-4} 指导老师：}***
	% \end{flushright}
\end{cabstract}


