% !Mode:: "TeX:UTF-8"

\begin{eabstract}

	Question Answer Matching is one of the most important research in Natural Language Processing.
	It mainly contains two subtasks, Answer Selection and Question Paraphrase Identification. 
	The objective of Answer Selection is to measure the semantic relevance between questions and answers, so as to optimize the recall quality of target answers in Question Answering (abbr., QA) scenarios. 
	Question Paraphrase Identification aims to determine the semantic equivalence between question pairs to improve the recall accuracy of the similar questions containing answer in QA scenarios. 
	Both of them are core technologies for the intelligent QA system and have been widely and practically utilized in search engines, community QA, intelligent customer service, etc. 
	Existing pre-trained language models are able to produce the unified encoding representation from text pairs, and the input structure and computation mode are suitable for handling Question Answer Matching. 
	However, the pre-trained language models still suffer from the limitations of insufficient fine-grained semantic perception and lack of robustness.

	Ground on the aforementioned problems, we conduct the specific research in the following three aspects: 
	1) The pre-trained language models fail to effectively leverage the independent semantic representation of word chunks, phrases, and clauses, 
	which tends to ignore the perception of fine-grained semantics in the matching. 
	Therefore, we propose a Multi-granularity Interaction Inference Network (abbr., MIIN),
	which encodes questions and answers with multi-granularity semantics to enrich the semantic information between sentences. 
	2) Although Fine-tuning the pre-trained language models are capable of improve its fine-grained semantic perception of specific tasks, 
	in fact this process greatly depends on the quantity and quality of fine-tuning data. 
	To this end, we propose a Directional Data Augmentation (abbr., DDA) strategy. 
	DDA utilizes the directional label to guide the generation network for automatic expansion of Question Paraphrase Identification dataset. 
	Compared with the traditional data augmentation methods, the samples generated by DDA are of higher quality and more semantic diversity. 
	3) Existing research lacks the in-depth exploration on the robustness.
	Especially in the Chinese domain, where data resources are relatively scarce, 
	the robustness of the models is more challenging to be evaluated. 
	Therefore, we construct a Question Paraphrase Identification dataset called CQM$_{robust}$, which is in line with the characteristics of Chinese linguistics. 
	CQM$_{robust}$ systematically evaluates the robustness of the models according to linguistic phenomena, 
	and assist us analyze the advantages and disadvantages of the existing pre-trained language models in Question Paraphrase Identification.
	
	We alleviate the problems of insufficient fine-grained semantic perception and robustness in Question Answer Matching from three perspectives: multi-granularity interaction, directional data augmentation, and robustness evaluation. 
	Our experiments on public datasets WPQA, LCQMC, and CQM$_{robust}$ all verify the effectiveness of the proposed methods.
	\vskip 10bp
	\noindent
	{\bf\zihao{-4} Key words: }
	Question Answer Matching,
	Answer Selection,
	Question Paraphrase Identification,
	Data Augmentation,
	Robustness

	\begin{flushright}
		{\bf\zihao{-4} Written by} Hongyu Zhu
		
		{\bf\zihao{-4} Supervised by} Min Zhang and Yu Hong
	\end{flushright}
	% \begin{flushright}
	% 	{\bf\zihao{-4} Written by} ***
		
	% 	{\bf\zihao{-4} Supervised by} ***
	% \end{flushright}
\end{eabstract}
